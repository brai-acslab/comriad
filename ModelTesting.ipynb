{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, Activation, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAlzeimer(plane):\n",
    "    if plane == 'coronal':\n",
    "        print(plane)\n",
    "        with h5py.File('data/Coronal-Augmented.h5', 'r') as hdf:\n",
    "            G1 = hdf.get('Train Data')\n",
    "            trainX = np.array(G1.get('x_train'))\n",
    "            trainY = np.array(G1.get('y_train'))\n",
    "            G2 = hdf.get('Test Data')\n",
    "            testX = np.array(G2.get('x_test'))\n",
    "            testY = np.array(G2.get('y_test'))\n",
    "\n",
    "    elif plane == 'sagittal':\n",
    "        print(plane)\n",
    "        with h5py.File('data/Sagittal-Augmented.h5', 'r') as hdf:\n",
    "            G1 = hdf.get('Train Data')\n",
    "            trainX = np.array(G1.get('x_train'))\n",
    "            trainY = np.array(G1.get('y_train'))\n",
    "            G2 = hdf.get('Test Data')\n",
    "            testX = np.array(G2.get('x_test'))\n",
    "            testY = np.array(G2.get('y_test'))\n",
    "    \n",
    "    else:\n",
    "        print(plane)\n",
    "        with h5py.File('data/Axial-Augmented.h5', 'r') as hdf:\n",
    "            G1 = hdf.get('Train Data')\n",
    "            trainX = np.array(G1.get('x_train'))\n",
    "            trainY = np.array(G1.get('y_train'))\n",
    "            G2 = hdf.get('Test Data')\n",
    "            testX = np.array(G2.get('x_test'))\n",
    "            testY = np.array(G2.get('y_test'))\n",
    "    \n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coronal\n",
      "axial\n",
      "sagittal\n"
     ]
    }
   ],
   "source": [
    "_, _, x_testC, y_testC = loadAlzeimer('coronal')\n",
    "_, _, x_testA, y_testA = loadAlzeimer('axial')\n",
    "_, _, x_testS, y_testS = loadAlzeimer('sagittal')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-1: Initialize xtest_c, xtest_a, xtest_s\n",
    "\n",
    "Step-2: Create a random vector of integers representing output labels [0,1,2,3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model for Coronal, Axial and Sagittal. \n",
    "modelC = Sequential()\n",
    "pretrained_model = tf.keras.applications.InceptionResNetV2(include_top=False,                                                        \n",
    "                                              input_shape=(218, 182, 3),\n",
    "                                              pooling='avg', classes=4,\n",
    "                                              weights='imagenet')\n",
    "for layer in pretrained_model.layers:\n",
    "   layer.trainable = False\n",
    "\n",
    "modelC.add(pretrained_model)\n",
    "modelC.add(Dropout(0.5))\n",
    "modelC.add(Flatten())\n",
    "modelC.add(BatchNormalization())\n",
    "modelC.add(Dense(2048, kernel_initializer='he_uniform'))\n",
    "modelC.add(BatchNormalization())\n",
    "modelC.add(Activation('relu'))\n",
    "modelC.add(Dropout(0.5))\n",
    "modelC.add(Dense(1024, kernel_initializer='he_uniform'))\n",
    "modelC.add(BatchNormalization())\n",
    "modelC.add(Activation('relu'))\n",
    "modelC.add(Dropout(0.5))\n",
    "modelC.add(Dense(4, activation='softmax'))\n",
    "#modelC.load_weights('weights/Xception_coronal.hdf5')\n",
    "modelC.load_weights('weights/InceptionResNetV2_coronal.hdf5')\n",
    "\n",
    "# modelC.add(Conv2D(16, (3, 3), input_shape=(218,182,1), activation='relu'))\n",
    "# modelC.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# #modelC.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# modelC.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# modelC.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelC.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelC.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelC.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# modelC.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# modelC.add(Conv2D(16, (1,1)))\n",
    "# modelC.add(Flatten())\n",
    "# modelC.add(Dense(4, activation = 'softmax'))\n",
    "# modelC.compile(loss='categorical_crossentropy',optimizer='adam',metrics =['acc'])\n",
    "# modelC.load_weights('weights/CNNScratch_coronal.hdf5')\n",
    "\n",
    "modelA = Sequential()\n",
    "pretrained_model = tf.keras.applications.InceptionResNetV2(include_top=False,                                                        \n",
    "                                               input_shape=(218, 182, 3),\n",
    "                                               pooling='avg', classes=4,\n",
    "                                               weights='imagenet')\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "modelA.add(pretrained_model)\n",
    "modelA.add(Dropout(0.5))\n",
    "modelA.add(Flatten())\n",
    "modelA.add(BatchNormalization())\n",
    "modelA.add(Dense(2048, kernel_initializer='he_uniform'))\n",
    "modelA.add(BatchNormalization())\n",
    "modelA.add(Activation('relu'))\n",
    "modelA.add(Dropout(0.5))\n",
    "modelA.add(Dense(1024, kernel_initializer='he_uniform'))\n",
    "modelA.add(BatchNormalization())\n",
    "modelA.add(Activation('relu'))\n",
    "modelA.add(Dropout(0.5))\n",
    "modelA.add(Dense(4, activation='softmax'))\n",
    "#modelA.load_weights('weights/Xception_axial.hdf5')\n",
    "modelA.load_weights('weights/InceptionResNetV2_axial.hdf5')\n",
    "\n",
    "# modelA.add(Conv2D(16, (3, 3), input_shape=(218,182,1), activation='relu'))\n",
    "# modelA.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# #modelA.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# modelA.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# modelA.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelA.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelA.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelA.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# modelA.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# modelA.add(Conv2D(16, (1,1)))\n",
    "# modelA.add(Flatten())\n",
    "# modelA.add(Dense(4, activation = 'softmax'))\n",
    "# modelA.compile(loss='categorical_crossentropy',optimizer='adam',metrics =['acc'])\n",
    "# modelA.load_weights('weights/CNNScratch_axial.hdf5')\n",
    "\n",
    "\n",
    "modelS = Sequential()\n",
    "pretrained_model = tf.keras.applications.InceptionResNetV2(include_top=False,                                                        \n",
    "                                               input_shape=(218, 182, 3),\n",
    "                                               pooling='avg', classes=4,\n",
    "                                               weights='imagenet')\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "modelS.add(pretrained_model)\n",
    "modelS.add(Dropout(0.5))\n",
    "modelS.add(Flatten())\n",
    "modelS.add(BatchNormalization())\n",
    "modelS.add(Dense(2048, kernel_initializer='he_uniform'))\n",
    "modelS.add(BatchNormalization())\n",
    "modelS.add(Activation('relu'))\n",
    "modelS.add(Dropout(0.5))\n",
    "modelS.add(Dense(1024, kernel_initializer='he_uniform'))\n",
    "modelS.add(BatchNormalization())\n",
    "modelS.add(Activation('relu'))\n",
    "modelS.add(Dropout(0.5))\n",
    "modelS.add(Dense(4, activation='softmax'))\n",
    "#modelS.load_weights('weights/Xception_sagittal.hdf5')\n",
    "modelS.load_weights('weights/InceptionResNetV2_sagittal.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "# modelS.add(Conv2D(16, (3, 3), input_shape=(218,182,1), activation='relu'))\n",
    "# modelS.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# #modelS.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# modelS.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# modelS.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelS.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelS.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# modelS.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# modelS.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# modelS.add(Conv2D(16, (1,1)))\n",
    "# modelS.add(Flatten())\n",
    "# modelS.add(Dense(4, activation = 'softmax'))\n",
    "# modelS.compile(loss='categorical_crossentropy',optimizer='adam',metrics =['acc'])\n",
    "# modelS.load_weights('weights/CNNScratch_sagittal.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 218, 182, 1) (4000, 218, 182, 1) (4000, 218, 182, 1)\n",
      "coronal prediction\n",
      "axial prediction\n",
      "sagittal prediction\n",
      "(4000, 4)\n"
     ]
    }
   ],
   "source": [
    "xtestCs = []\n",
    "xtestAs = []\n",
    "xtestSs = []\n",
    "#np.random.seed(103)\n",
    "labels = np.random.randint(0, 4, size=4000)\n",
    "#print(labels)\n",
    "numClasses = len(np.unique(labels))\n",
    "idxC = [np.where(y_testC == i)[0] for i in range(0, numClasses)]\n",
    "idxA = [np.where(y_testA == i)[0] for i in range(0, numClasses)]\n",
    "idxS = [np.where(y_testS == i)[0] for i in range(0, numClasses)]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "   #print(i)\n",
    "   index = labels[i] #for every label in the test labels. \n",
    "   imgIndex = np.random.choice(idxC[index]) #generate image index belonging to Coronal plane for the same label. \n",
    "   #print('c index',imgIndex)\n",
    "   xtestCs.append(x_testC[imgIndex]) #pick the image belonging to the same label from coronal plane. \n",
    "\n",
    "   imgIndex = np.random.choice(idxA[index]) #generate image index belonging to Axial plane for the same label. \n",
    "   #print('a index',imgIndex)\n",
    "   xtestAs.append(x_testA[imgIndex]) #pick the image belonging to the same label from axial plane. \n",
    "   \n",
    "   imgIndex = np.random.choice(idxS[index]) #generate image index belonging to Sagittal plane for the same label. \n",
    "   #print('s index',imgIndex)\n",
    "   xtestSs.append(x_testS[imgIndex]) #pick the image belonging to the same label from sagital plane. \n",
    "\n",
    "#convert the lists to np arrays. \n",
    "xtestCs = np.array(xtestCs)\n",
    "xtestAs = np.array(xtestAs)\n",
    "xtestSs = np.array(xtestSs)\n",
    "print(xtestCs.shape,xtestAs.shape,xtestSs.shape)\n",
    "\n",
    "\n",
    "#get the data ready for prediction using the loaded models. \n",
    "xtestCs = np.repeat(xtestCs, 3,axis=3)\n",
    "xtestAs = np.repeat(xtestAs, 3,axis=3)\n",
    "xtestSs = np.repeat(xtestSs, 3,axis=3)\n",
    "\n",
    "#prediction using coronal plane [using the best weights]\n",
    "print('coronal prediction')\n",
    "predictionCoronal = modelC.predict(xtestCs)\n",
    "print('axial prediction')\n",
    "predictionAxial = modelA.predict(xtestAs)\n",
    "print('sagittal prediction')\n",
    "predictionSagittal = modelS.predict(xtestSs)\n",
    "\n",
    "print(predictionCoronal.shape)\n",
    "y_pred_coronal =np.argmax(predictionCoronal,axis=1)\n",
    "y_pred_axial = np.argmax(predictionAxial,axis=1)\n",
    "y_pred_sagittal = np.argmax(predictionSagittal,axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fusion of all planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================Ensemble=============================================\n",
      "ensemble accuracy = 0.574\n",
      "Specificity or TNR 0.8578750765471616\n",
      "Sensitivity or TPR or Recall 0.5737957818156407\n",
      "FNR  0.4262042181843593\n",
      "FPR 0.14212492345283845\n",
      "================================== Coronal ==============================================\n",
      "Accuracy in Coronal Plane 0.3845\n",
      "Specificity or TNR 0.7944432303811768\n",
      "Sensitivity or TPR or Recall 0.3832807341201564\n",
      "FNR  0.6167192658798436\n",
      "FPR 0.2055567696188232\n",
      "================================== axial ==============================================\n",
      "Accuracy in Axial Plane 0.41275\n",
      "Specificity or TNR 0.7944432303811768\n",
      "Sensitivity or TPR or Recall 0.3832807341201564\n",
      "FNR  0.6167192658798436\n",
      "FPR 0.2055567696188232\n",
      "================================== Sagittal ==============================================\n",
      "Accuracy in Sagittal Plane 0.46875\n",
      "Specificity or TNR 0.8229538728977596\n",
      "Sensitivity or TPR or Recall 0.4695714566952285\n",
      "FNR  0.5304285433047715\n",
      "FPR 0.17704612710224044\n"
     ]
    }
   ],
   "source": [
    "preds = np.stack([predictionCoronal,predictionAxial, predictionSagittal], axis=0)\n",
    "summed = np.sum(preds, axis=0) #computes the sum of probability by all 3 models for each class\n",
    "ensemble_prediction = np.argmax(summed, axis=1) \n",
    "Ac_e = accuracy_score(labels, ensemble_prediction)\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "print(\"===================================Ensemble=============================================\")\n",
    "print('ensemble accuracy =', Ac_e)\n",
    "\n",
    "mcm = multilabel_confusion_matrix(y_true=labels, y_pred=ensemble_prediction, labels=[0,1,2,3], samplewise=False)\n",
    "tn = mcm[:,0,0]\n",
    "tp = mcm[:,1,1]\n",
    "fp = mcm[:,0,1]\n",
    "fn = mcm[:,1,0]\n",
    "specificity = tn/(tn+fp)\n",
    "Sp_e = np.mean(specificity)\n",
    "print(\"Specificity or TNR\", Sp_e)\n",
    "sensitivity = tp/(tp+fn)\n",
    "Se_e = np.mean(sensitivity)\n",
    "print(\"Sensitivity or TPR or Recall\",Se_e)\n",
    "FNR_e = 1-np.mean(sensitivity)\n",
    "print(\"FNR \", FNR_e)\n",
    "FPR_e = 1-np.mean(specificity)\n",
    "print(\"FPR\", FPR_e)\n",
    "\n",
    "print(\"================================== Coronal ==============================================\")\n",
    "mcm = multilabel_confusion_matrix(y_true=labels, y_pred=y_pred_coronal, labels=[0,1,2,3], samplewise=False)\n",
    "tn = mcm[:,0,0]\n",
    "tp = mcm[:,1,1]\n",
    "fp = mcm[:,0,1]\n",
    "fn = mcm[:,1,0]\n",
    "specificity = tn/(tn+fp)\n",
    "Ac_c = accuracy_score(y_true=labels, y_pred=y_pred_coronal)\n",
    "print('Accuracy in Coronal Plane',Ac_c)\n",
    "print(\"Specificity or TNR\", np.mean(specificity))\n",
    "sensitivity = tp/(tp+fn)\n",
    "print(\"Sensitivity or TPR or Recall\", np.mean(sensitivity))\n",
    "print(\"FNR \", 1-np.mean(sensitivity))\n",
    "print(\"FPR\", 1-np.mean(specificity))\n",
    "\n",
    "Sp_c = np.mean(specificity)\n",
    "Se_c = np.mean(sensitivity)\n",
    "FNR_c = 1-np.mean(sensitivity)\n",
    "FPR_c = 1-np.mean(specificity)\n",
    "\n",
    "print(\"================================== axial ==============================================\")\n",
    "mcm = multilabel_confusion_matrix(y_true=labels, y_pred=y_pred_axial, labels=[0,1,2,3], samplewise=False)\n",
    "tn = mcm[:,0,0]\n",
    "tp = mcm[:,1,1]\n",
    "fp = mcm[:,0,1]\n",
    "fn = mcm[:,1,0]\n",
    "specificity = tn/(tn+fp)\n",
    "Ac_a = accuracy_score(y_true=labels, y_pred=y_pred_axial)\n",
    "print('Accuracy in Axial Plane',Ac_a)\n",
    "Sp_a = np.mean(specificity) \n",
    "print(\"Specificity or TNR\", Sp_c)\n",
    "sensitivity = tp/(tp+fn)\n",
    "Se_a = np.mean(sensitivity)\n",
    "print(\"Sensitivity or TPR or Recall\",Se_c)\n",
    "FNR_a = 1-np.mean(sensitivity)\n",
    "print(\"FNR \", FNR_c)\n",
    "FPR_a = 1-np.mean(specificity)\n",
    "print(\"FPR\", FPR_c)\n",
    "print(\"================================== Sagittal ==============================================\")\n",
    "mcm = multilabel_confusion_matrix(y_true=labels, y_pred=y_pred_sagittal, labels=[0,1,2,3], samplewise=False)\n",
    "tn = mcm[:,0,0]\n",
    "tp = mcm[:,1,1]\n",
    "fp = mcm[:,0,1]\n",
    "fn = mcm[:,1,0]\n",
    "specificity = tn/(tn+fp)\n",
    "Ac_s = accuracy_score(y_true=labels, y_pred=y_pred_sagittal)\n",
    "print('Accuracy in Sagittal Plane',Ac_s)\n",
    "Sp_s =  np.mean(specificity)\n",
    "print(\"Specificity or TNR\",Sp_s)\n",
    "sensitivity = tp/(tp+fn)\n",
    "Se_s = np.mean(sensitivity)\n",
    "print(\"Sensitivity or TPR or Recall\",Se_s)\n",
    "FNR_s = 1-np.mean(sensitivity)\n",
    "print(\"FNR \",FNR_s )\n",
    "FPR_s =  1-np.mean(specificity)\n",
    "print(\"FPR\",FPR_s)\n",
    "\n",
    "\n",
    "metrics = {'Accuracy':[Ac_c, Ac_a,Ac_s, Ac_e],\n",
    "           'Specificity':[Sp_c,Sp_a,Sp_s,Sp_e],\n",
    "           'Sensitivity':[Se_c,Se_a,Se_s,Se_e],\n",
    "           'FNR':[FNR_c, FNR_a, FNR_s, FNR_e],\n",
    "           'FPR':[FPR_c, FPR_a, FPR_s, FPR_e]\n",
    "           }\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "df.index = ['coronal', 'axial', 'sagittal', 'combiplane']\n",
    "#print (df)\n",
    "df.to_csv('testing-metrics//' + 'InceptionResNetV2-t-test-run-5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(labels, ensemble_prediction)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), cbar=False, linewidth=0.5,linecolor=\"black\",fmt='')\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "plt.savefig(\"testing-cm/CM-Ensemble-CNN-ScratchO-8000.pdf\")\n",
    "\n",
    "#Coronal ----------------------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(labels, y_pred_coronal)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), cbar=False, linewidth=0.5,linecolor=\"black\",fmt='')\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "plt.savefig(\"testing-cm/CM-coronal-CNN-ScratchO-8000.pdf\")\n",
    "\n",
    "#axial ----------------------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(labels, y_pred_axial)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), cbar=False, linewidth=0.5,linecolor=\"black\",fmt='')\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "plt.savefig(\"testing-cm/CM-axial-CNN-ScratchO-8000.pdf\")\n",
    "\n",
    "#sagittal ----------------------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(labels, y_pred_coronal)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), cbar=False, linewidth=0.5,linecolor=\"black\",fmt='')\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "plt.savefig(\"testing-cm/CM-sagittal-CNN-ScratchO-8000.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
